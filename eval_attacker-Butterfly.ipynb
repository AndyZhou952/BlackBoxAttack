{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c12f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.base import eval_accuracy\n",
    "from utils.base import get_correct_predictions_subset\n",
    "from utils.data import create_butterfly_dataset\n",
    "from utils.data import create_imagenet_dataset\n",
    "from model.butterfly_classifier import DenseNet121\n",
    "from algo.attacker import adversarial_generator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff7697",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# (0) Download Butterfly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d gpiosenka/butterfly-images40-species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72378467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('butterfly-images40-species.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/butterfly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26846483",
   "metadata": {},
   "source": [
    "# (1) Process Butterfly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699e46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, normal_mapping, reverse_mapping, sample_img_dataset = create_butterfly_dataset()\n",
    "assert len(trainset) == 12594, 'Size of train set not match'\n",
    "assert len(testset) == 500, 'Size of test set not match'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa8ca7",
   "metadata": {},
   "source": [
    "# (2) Import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c3997e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNet121(num_classes=len(normal_mapping)).to('cuda')\n",
    "model.load_state_dict(torch.load('./model/states/butterfly_classifier.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad53eb",
   "metadata": {},
   "source": [
    "# (3) Evaluate Untargeted Adversarial Examples\n",
    "\n",
    "We also subset the parts where the model could provide correct predictions to attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b21759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 0.9640\n",
      "Number of correctly predicted samples: 482\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy, correct_subset = get_correct_predictions_subset(model, testset, batch_size=100)\n",
    "print('Accuracy on test set is {:.4f}'.format(accuracy))\n",
    "print('Number of correctly predicted samples:', len(correct_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6689fe9",
   "metadata": {},
   "source": [
    "# (4) Parameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4238850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters definition\n",
    "batch_size = 32\n",
    "query_limit = 30000 # max attack limit \n",
    "LO_query_limit = 3000000 # max attack limit \n",
    "search_var = 1e-3 # amount to perturb the input image\n",
    "sample_num = 50 # 2*sample_num for estimating gradient\n",
    "bound = 0.1 # the l-infinity distance between the adversarial example and the input image\n",
    "# partial information paramters + lebel-only parameters\n",
    "epsilon = 0.5 # initial searching range from the target image\n",
    "delta = 0.01 # rate to decrease epsilon\n",
    "eta_max = 0.02 # maximum learning rate\n",
    "eta_min = 0.01 # minimum learning rate\n",
    "k = 5 # information access\n",
    "# label-only parameter\n",
    "mu = 0.001 # radius for sampling ball\n",
    "m = 50 # 2*number of sample for proxy score\n",
    "#correct_subset_loader = DataLoader(correct_subset, batch_size = batch_size, shuffle = False)\n",
    "correct_subset_loader = DataLoader(correct_subset, batch_size = 2, shuffle = False)\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d05da",
   "metadata": {},
   "source": [
    "# (5) Query-Limited Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c770a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True], device='cuda:0')\n",
      "tensor(2., device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from utils.base import quick_predict\n",
    "\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "success_count = 0\n",
    "query_counts = []\n",
    "adv_images = []\n",
    "with torch.no_grad():\n",
    "    for batch in correct_subset_loader:\n",
    "        images = batch[0]\n",
    "        target_classes = batch[1].to('cuda')\n",
    "        adv_image_batch, query_count_batch = adversarial_generator(model, target_classes, images, \n",
    "                                                                 search_var, sample_num,\n",
    "                                                                bound, lr, query_limit)\n",
    "        query_counts.append(query_count_batch)\n",
    "        adv_images.append(adv_image_batch)\n",
    "        \n",
    "        adv_class = quick_predict(model, adv_image_batch)\n",
    "        success_count += (adv_class != target_classes).to(float).sum()\n",
    "    \n",
    "adv_image_all = torch.concat(adv_images, dim = 0)\n",
    "query_count_all = torch.concat(query_counts, dim = 0)\n",
    "torch.save(adv_image_all, \"QL_adv_img.pt\")\n",
    "torch.save(query_count_all, \"QL_query.pt\")\n",
    "print('Success count is {}, total count is {}, success attack rate is {}'.format(success_count, len(correct_subset), success_count /len(correct_subset) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d888eec",
   "metadata": {},
   "source": [
    "# (6) Partial-Information Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef3ab39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/482 [00:47<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count is 1, total count is 482, success attack rate is 0.004149377593360996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from algo.attacker import PIA_adversarial_generator\n",
    "from algo.defender import PartialInfo\n",
    "from tqdm import trange\n",
    "\n",
    "success_count_PIA = 0\n",
    "query_counts_PIA = []\n",
    "adv_images_PIA = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in trange(len(correct_subset)):\n",
    "        \n",
    "        images = correct_subset[i][0].unsqueeze(0)\n",
    "        # images = batch[0]\n",
    "        adv_image_batch, query_count_batch = PIA_adversarial_generator(model, images, sample_img_dataset,\n",
    "                                                                      epsilon, delta, search_var,\n",
    "                                                                      sample_num, eta_max, eta_min,\n",
    "                                                                      bound, k, query_limit, label_only = False)\n",
    "        query_counts_PIA.append(query_count_batch)\n",
    "        adv_images_PIA.append(adv_image_batch)\n",
    "        \n",
    "        \n",
    "        reach_bound = (query_count_batch < query_limit).to('cuda')\n",
    "        successful_attack = (quick_predict(model, adv_image_batch) != correct_subset[i][1]).to('cuda')\n",
    "        success_count_PIA += (successful_attack * reach_bound).to(int).sum()\n",
    "        \n",
    "adv_image_all_pia = torch.concat(adv_images_PIA, dim = 0)\n",
    "query_count_all_pia = torch.concat(query_counts_PIA, dim = 0)\n",
    "torch.save(adv_image_all_pia, \"PIA_adv_img.pt\")\n",
    "torch.save(query_count_all_pia, \"PIA_query.pt\")\n",
    "print('Success count is {}, total count is {}, success attack rate is {}'.format(success_count_PIA, len(correct_subset), success_count_PIA /len(correct_subset) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7875d6",
   "metadata": {},
   "source": [
    "# (7) Label-only Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "success_count_LO = 0\n",
    "query_counts_LO = []\n",
    "adv_images_LO = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in trange(2):\n",
    "        images = correct_subset[i][0].unsqueeze(0)\n",
    "        adv_image_batch, query_count_batch = PIA_adversarial_generator(model, images, sample_img_dataset,\n",
    "                                                                      epsilon, delta, search_var,\n",
    "                                                                      sample_num, eta_max, eta_min,\n",
    "                                                                      bound, k, query_limit=LO_query_limit, label_only = True, mu = mu, m = m) # different query_limit\n",
    "        query_counts_LO.append(query_count_batch)\n",
    "        adv_images_LO.append(adv_image_batch)\n",
    "        \n",
    "        reach_bound = (query_count_batch < LO_query_limit).to('cuda')\n",
    "        successful_attack = (quick_predict(model, adv_image_batch) != correct_subset[i][1]).to('cuda')\n",
    "        success_count_LO += (successful_attack * reach_bound).to(int).sum()\n",
    "        break\n",
    "        \n",
    "adv_image_all_lo = torch.concat(adv_images_LO, dim = 0)\n",
    "query_count_all_lo = torch.concat(query_counts_LO, dim = 0)\n",
    "torch.save(adv_image_all_lo, \"LO_adv_img.pt\")\n",
    "torch.save(query_count_all_lo, \"LO_query.pt\")\n",
    "print('Success count is {}, total count is {}, success attack rate is {}'.format(success_count_LO, 2, success_count_LO /2 ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
