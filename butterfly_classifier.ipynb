{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2932423-ac8b-4aaa-8c2d-eb935794c992",
   "metadata": {},
   "source": [
    "# (0) Download Butterfly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d5a02a6-6dfd-4ef5-ba15-91984d078c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jovyan/.kaggle/kaggle.json'\n",
      "Downloading butterfly-images40-species.zip to /home/jovyan/work/project\n",
      " 99%|███████████████████████████████████████▌| 395M/399M [00:11<00:00, 44.1MB/s]\n",
      "100%|████████████████████████████████████████| 399M/399M [00:11<00:00, 36.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d gpiosenka/butterfly-images40-species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde345c7-f216-4d3a-b79d-4266b766f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('butterfly-images40-species.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/butterfly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350da92",
   "metadata": {},
   "source": [
    "# (1) Process Butterfly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455c0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466d5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path_label, transform=None):\n",
    "        self.path_label = path_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.path_label[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "# Create dataset from raw structure obtained from Kaggle\n",
    "# (1): Download dataset fron Kaggle: https://www.kaggle.com/datasets/gpiosenka/butterfly-images40-species?select=train\n",
    "# (2): Unzip the downloaded dataset to './data/butterfly'\n",
    "# (3): Run the function\n",
    "def create_dataset(path = './data/butterfly/'):\n",
    "    transform = transforms.Compose([\n",
    "                                    transforms.Resize((224,224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    train_path = path + 'train'\n",
    "    test_path = path + 'test'\n",
    "    \n",
    "    class_names=sorted(os.listdir(train_path))\n",
    "    N=list(range(len(class_names)))\n",
    "    normal_mapping=dict(zip(class_names,N)) \n",
    "    reverse_mapping=dict(zip(N,class_names))\n",
    "\n",
    "    paths0=[]\n",
    "    for dirname, _, filenames in os.walk(train_path):\n",
    "        for filename in filenames:\n",
    "            if filename[-4:]=='.jpg':\n",
    "                path=os.path.join(dirname, filename)\n",
    "                label=dirname.split('\\\\')[-1]\n",
    "                if label == '.ipynb_checkpoints':\n",
    "                    continue\n",
    "                paths0+=[(path,normal_mapping[label])]\n",
    "            \n",
    "    tpaths0=[]\n",
    "    for dirname, _, filenames in os.walk(test_path):\n",
    "        for filename in filenames:\n",
    "            if filename[-4:]=='.jpg':\n",
    "                path=os.path.join(dirname, filename)\n",
    "                label=dirname.split('\\\\')[-1]\n",
    "                if label == '.ipynb_checkpoints':\n",
    "                    continue\n",
    "                tpaths0+=[(path,normal_mapping[label])]\n",
    "\n",
    "    random.shuffle(paths0)            \n",
    "    random.shuffle(tpaths0)  \n",
    "\n",
    "    trainset = ImageDataset(paths0, transform)\n",
    "    testset = ImageDataset(tpaths0, transform)\n",
    "    \n",
    "    return trainset, testset, normal_mapping, reverse_mapping\n",
    "\n",
    "\n",
    "trainset, testset, normal_mapping, reverse_mapping = create_dataset()\n",
    "assert len(trainset) == 12594, 'Size of train set not match'\n",
    "assert len(testset) == 500, 'Size of test set not match'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a4c10",
   "metadata": {},
   "source": [
    "# (2) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f994de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional block with layer norm\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dropout, padding=0, stride=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "        # self.norm = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.dropout = nn.Dropout2d(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = self.norm(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# CNN Classifier\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64, kernel_size=3, dropout=0.2, padding=1, stride=1, bias=True)\n",
    "        self.conv2 = ConvBlock(in_channels=64, out_channels=128, kernel_size=3, dropout=0.2, padding=1, stride=1, bias=True)\n",
    "        self.conv3 = ConvBlock(in_channels=128, out_channels=256, kernel_size=3, dropout=0.2, padding=1, stride=1, bias=True)\n",
    "        self.fc1 = torch.nn.LazyLinear(out_features=24)\n",
    "        self.fc2 = torch.nn.LazyLinear(out_features=64)        \n",
    "        self.fc3 = torch.nn.LazyLinear(out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x ,kernel_size=2)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x ,kernel_size=2)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x ,kernel_size=2)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af4ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, criterion, epoch, device):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (inp, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inp, label = inp.to(device), label.to(device)\n",
    "        output = model(inp)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inp, label) in enumerate(test_loader):\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            output = model(inp)\n",
    "            loss = criterion(output, label)\n",
    "            test_loss += loss.item()\n",
    "    return train_loss / len(train_loader), test_loss / len(test_loader)\n",
    "    \n",
    "\n",
    "# Params\n",
    "batch_size=100\n",
    "lr = 0.0001\n",
    "device='cuda'\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset=testset, batch_size=batch_size)\n",
    "\n",
    "# Model\n",
    "model = Classifier(in_channels=3, num_classes=len(normal_mapping))\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# load states\n",
    "# model.load_state_dict(torch.load('butterfly_classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2069ca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:46<06:56, 46.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train: 4.554944878532773, Test: 4.4601034164428714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [01:21<05:16, 39.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train: 4.283979308037531, Test: 4.061660385131836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [01:56<04:24, 37.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train: 3.86335817972819, Test: 3.61726393699646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [02:29<03:34, 35.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train: 3.503167006704542, Test: 3.310771417617798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [03:01<02:52, 34.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train: 3.2363169079735163, Test: 3.0605010986328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [03:34<02:15, 33.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train: 3.0235348031634377, Test: 2.89745979309082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [04:06<01:40, 33.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train: 2.8426545971915838, Test: 2.7798788070678713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [04:39<01:06, 33.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train: 2.686428416342962, Test: 2.6336065769195556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [05:11<00:32, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train: 2.5441583622069586, Test: 2.564341926574707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [05:44<00:00, 34.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train: 2.414930653950525, Test: 2.4758275985717773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_hist = list()\n",
    "test_hist = list()\n",
    "for epoch in trange(1, 10 + 1):\n",
    "    train_loss, test_loss = train(model, train_loader, test_loader, optimizer, criterion, epoch, device=device)\n",
    "    train_hist.append(train_loss)\n",
    "    test_hist.append(test_loss)\n",
    "    print('Epoch {}: Train: {}, Test: {}'.format(epoch, train_loss, test_loss))\n",
    "    \n",
    "torch.save(model.state_dict(), 'butterfly_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a1afb-2b55-4977-81f5-c53415613b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
