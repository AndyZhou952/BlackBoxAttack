{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2932423-ac8b-4aaa-8c2d-eb935794c992",
   "metadata": {},
   "source": [
    "# (0) Download Butterfly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d5a02a6-6dfd-4ef5-ba15-91984d078c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jovyan/.kaggle/kaggle.json'\n",
      "Downloading butterfly-images40-species.zip to /home/jovyan/work/project\n",
      " 99%|███████████████████████████████████████▌| 395M/399M [00:11<00:00, 44.1MB/s]\n",
      "100%|████████████████████████████████████████| 399M/399M [00:11<00:00, 36.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d gpiosenka/butterfly-images40-species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde345c7-f216-4d3a-b79d-4266b766f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('butterfly-images40-species.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/butterfly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350da92",
   "metadata": {},
   "source": [
    "# (1) Process Butterfly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455c0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466d5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset Class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path_label, transform=None):\n",
    "        self.path_label = path_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.path_label[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "# Create dataset from raw structure obtained from Kaggle\n",
    "# (1): Download dataset fron Kaggle: https://www.kaggle.com/datasets/gpiosenka/butterfly-images40-species?select=train\n",
    "# (2): Unzip the downloaded dataset to './data/butterfly'\n",
    "# (3): Run the function\n",
    "def create_dataset(path = './data/butterfly/'):\n",
    "    train_path = path + 'train'\n",
    "    test_path = path + 'test'\n",
    "    \n",
    "    class_names=sorted(os.listdir(train_path))\n",
    "    N=list(range(len(class_names)))\n",
    "    normal_mapping=dict(zip(class_names,N)) \n",
    "    reverse_mapping=dict(zip(N,class_names))\n",
    "\n",
    "    paths0=[]\n",
    "    for dirname, _, filenames in os.walk(train_path):\n",
    "        for filename in filenames:\n",
    "            if filename[-4:]=='.jpg':\n",
    "                path=os.path.join(dirname, filename)\n",
    "                label=dirname.split('/')[-1]\n",
    "                if label == '.ipynb_checkpoints':\n",
    "                    continue\n",
    "                paths0+=[(path,normal_mapping[label])]\n",
    "            \n",
    "    tpaths0=[]\n",
    "    for dirname, _, filenames in os.walk(test_path):\n",
    "        for filename in filenames:\n",
    "            if filename[-4:]=='.jpg':\n",
    "                path=os.path.join(dirname, filename)\n",
    "                label=dirname.split('/')[-1]\n",
    "                if label == '.ipynb_checkpoints':\n",
    "                    continue\n",
    "                tpaths0+=[(path,normal_mapping[label])]\n",
    "\n",
    "    random.shuffle(paths0)            \n",
    "    random.shuffle(tpaths0)  \n",
    "\n",
    "    \n",
    "    trainset = ImageDataset(paths0, transform)\n",
    "    testset = ImageDataset(tpaths0, transform)\n",
    "    \n",
    "    return trainset, testset, normal_mapping, reverse_mapping\n",
    "\n",
    "\n",
    "trainset, testset, normal_mapping, reverse_mapping = create_dataset()\n",
    "assert len(trainset) == 12594, 'Size of train set not match'\n",
    "assert len(testset) == 500, 'Size of test set not match'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a4c10",
   "metadata": {},
   "source": [
    "# (2) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f994de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional block with layer norm\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dropout, padding=0, stride=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "        # self.norm = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.dropout = nn.Dropout2d(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = self.norm(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# CNN Classifier\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64, kernel_size=3, dropout=0, padding=1, stride=1, bias=True)\n",
    "        self.conv2 = ConvBlock(in_channels=64, out_channels=128, kernel_size=3, dropout=0, padding=1, stride=1, bias=True)\n",
    "        self.conv3 = ConvBlock(in_channels=128, out_channels=256, kernel_size=3, dropout=0, padding=1, stride=1, bias=True)\n",
    "        self.conv4 = ConvBlock(in_channels=256, out_channels=512, kernel_size=3, dropout=0, padding=1, stride=1, bias=True)\n",
    "        self.fc = torch.nn.LazyLinear(out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.silu(self.conv1(x))\n",
    "        x = F.max_pool2d(x ,kernel_size=2)\n",
    "        \n",
    "        x = F.silu(self.conv2(x))\n",
    "        x = F.max_pool2d(x ,kernel_size=2)\n",
    "        \n",
    "        x = F.silu(self.conv3(x))\n",
    "        x = F.max_pool2d(x ,kernel_size=2)\n",
    "        \n",
    "        x = F.silu(self.conv4(x))\n",
    "        x = F.max_pool2d(x ,kernel_size=2)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        print(x.size())\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af4ca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epoch, device):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (inp, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inp, label = inp.to(device), label.to(device)\n",
    "        output = model(inp)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train({})[{:.0f}%]: Loss: {:.4f}'.format(\n",
    "                epoch, 100. * batch_idx / len(train_loader), train_loss/(batch_idx+1)))\n",
    "            \n",
    "batch_size=20\n",
    "lr = 0.001\n",
    "device='cuda'\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=batch_size)\n",
    "model = Classifier(in_channels=3, num_classes=len(normal_mapping))\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069ca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train(1)[0%]: Loss: 4.6068\n",
      "Train(1)[16%]: Loss: 4.0587\n",
      "Train(1)[32%]: Loss: 3.5848\n"
     ]
    }
   ],
   "source": [
    "for epoch in trange(1, 10 + 1):\n",
    "    train(model, train_loader, optimizer, criterion, epoch, device=device)\n",
    "    scheduler.step()\n",
    "torch.save(model.state_dict(), 'butterfly_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2754ffa-0aa6-436c-a1b5-ff552f2da043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
